{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация на FashionMNIST (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:56:53.736551Z",
     "start_time": "2019-11-12T16:56:53.697784Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WGoorsK6mPZP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "import time\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:56:53.930939Z",
     "start_time": "2019-11-12T16:56:53.927524Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WIcNCt4ZmPZZ"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:11:52.832124Z",
     "start_time": "2019-11-12T17:11:52.776322Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Kw5Kv2i6mPZu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "train_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T16:58:37.613945Z",
     "start_time": "2019-11-12T16:58:37.608386Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SKhbDXt_mPZ0",
    "outputId": "1f0ddd67-aa80-4da2-b6c1-45a3c7de33f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:27:43.689461Z",
     "start_time": "2019-11-12T17:27:43.684254Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "V7qWC2EbmPZ5"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "                      nn.BatchNorm2d(32),\n",
    "                      nn.ReLU(),\n",
    "                      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "                      nn.BatchNorm2d(64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.MaxPool2d(2),\n",
    "                      nn.Flatten(),\n",
    "                      nn.Linear(in_features=2304, out_features=120),\n",
    "                      nn.BatchNorm1d(120),nn.Dropout(), nn.ReLU(),\n",
    "                      nn.Linear(in_features=120, out_features=84),\n",
    "                      nn.BatchNorm1d(84), nn.Dropout(.7), \n",
    "                      nn.Linear(in_features=84, out_features=10)\n",
    "                      )\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T17:27:43.957461Z",
     "start_time": "2019-11-12T17:27:43.952900Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "fDqkL214mPZ7"
   },
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss()\n",
    "trainer_1 = torch.optim.AdamW(model.parameters(), lr=.01)\n",
    "trainer_2 = torch.optim.SGD(model.parameters(), lr=.001)\n",
    "num_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X, y, model, dict, trainer=False):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    if trainer:\n",
    "        trainer.zero_grad()\n",
    "    predictions = model(X)\n",
    "    loss = loss_f(predictions, y)\n",
    "    loss.backward()\n",
    "    if trainer:\n",
    "        trainer.step()\n",
    "    dict = {'loss':(dict['loss']+loss.item()), \n",
    "            'tp':(dict['tp']+(predictions.argmax(dim=1) == y).sum().item()), \n",
    "            'iters':(dict['iters']+1), \n",
    "            'len':(dict['len']+len(X))}\n",
    "    return dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epochs |  Time   | Train Adam loss | Train SGD loss | Test loss | Train Adam acc | Train SGD acc | Test acc |\n",
      "|   0    | 68.7784 |     0.5664      |     0.4047     |  0.3307   |    79.9367%    |   86.0683%    | 88.7000% |\n",
      "|   1    | 68.5101 |     0.3828      |     0.3424     |  0.2909   |    87.0217%    |   88.3817%    | 89.4700% |\n",
      "|   2    | 68.0033 |     0.3288      |     0.2940     |  0.2621   |    88.8317%    |   89.8000%    | 90.3900% |\n",
      "|   3    | 68.0298 |     0.2985      |     0.2729     |  0.2528   |    89.8817%    |   90.6750%    | 90.8300% |\n",
      "|   4    | 67.9169 |     0.2822      |     0.2633     |  0.2513   |    90.2700%    |   90.9700%    | 91.0600% |\n",
      "|   5    | 67.4403 |     0.2628      |     0.2374     |  0.2359   |    90.9600%    |   91.8267%    | 91.5100% |\n",
      "|   6    | 67.4809 |     0.2492      |     0.2414     |  0.2404   |    91.3417%    |   91.7533%    | 91.6100% |\n",
      "|   7    | 68.7975 |     0.2379      |     0.2271     |  0.2396   |    91.7133%    |   92.0650%    | 91.6100% |\n",
      "|   8    | 69.7722 |     0.2320      |     0.2206     |  0.2340   |    92.0367%    |   92.3867%    | 91.7700% |\n",
      "|   9    | 69.2604 |     0.2229      |     0.2081     |  0.2427   |    92.2367%    |   92.6683%    | 91.5000% |\n",
      "|   10   | 69.0150 |     0.2125      |     0.2073     |  0.2432   |    92.5533%    |   92.7700%    | 91.7000% |\n",
      "|   11   | 68.3533 |     0.2031      |     0.1864     |  0.2371   |    92.8983%    |   93.5800%    | 92.1700% |\n",
      "|   12   | 67.3533 |     0.1970      |     0.1904     |  0.2433   |    93.0783%    |   93.2217%    | 91.8100% |\n",
      "|   13   | 70.0195 |     0.1923      |     0.1839     |  0.2465   |    93.2767%    |   93.4933%    | 92.0600% |\n",
      "|   14   | 66.4506 |     0.1874      |     0.1763     |  0.2532   |    93.3350%    |   93.7767%    | 91.9400% |\n"
     ]
    }
   ],
   "source": [
    "print('|{: ^8}|{: ^9}|{: ^17}|{: ^16}|{: ^11}|{: ^16}|{: ^15}|{: ^10}|'\\\n",
    "      .format('Epochs','Time','Train Adam loss','Train SGD loss',\n",
    "              'Test loss','Train Adam acc','Train SGD acc','Test acc'))\n",
    "for epoch in range(num_epochs):\n",
    "    start=time.time()\n",
    "    model.train()\n",
    "    first_train = {'loss':0, 'tp':0, 'iters':0, 'len':0}\n",
    "    for X,y in train:\n",
    "        first_train = training(X, y, model, first_train, trainer_1)\n",
    "        \n",
    "    second_train = {'loss':0, 'tp':0, 'iters':0, 'len':0}\n",
    "    for X,y in train:\n",
    "        second_train = training(X, y, model, second_train, trainer_2)\n",
    "    \n",
    "    model.eval()\n",
    "    last_train = {'loss':0, 'tp':0, 'iters':0, 'len':0}\n",
    "    for X,y in test:\n",
    "        last_train = training(X, y, model, last_train, )\n",
    "        \n",
    "    print('|{: ^8}|{: ^9.4f}|{: ^17.4f}|{: ^16.4f}|{: ^11.4f}|{: ^16.4%}|{: ^15.4%}|{: ^10.4%}|'\\\n",
    "          .format(epoch, time.time()-start,  \n",
    "                  first_train['loss']/first_train['iters'],\n",
    "                  second_train['loss']/second_train['iters'], \n",
    "                  last_train['loss']/last_train['iters'],\n",
    "                  first_train['tp']/first_train['len'],\n",
    "                  second_train['tp']/second_train['len'],\n",
    "                  last_train['tp']/last_train['len']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetPipeline:\n",
    "    def __init__(self, train_loader, test_loader, model, num_epochs, \n",
    "                 first_opt, lr1, criterion=nn.CrossEntropyLoss(), second_opt=False, lr2=False):\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.model = model\n",
    "        self.num_epochs = num_epochs\n",
    "        self.criterion = criterion\n",
    "        self.first_opt = first_opt\n",
    "        self.lr1 = lr1\n",
    "        self.second_opt = second_opt\n",
    "        self.lr2 = lr2\n",
    "        \n",
    "    def train_steps(self):\n",
    "        trainer_1 = self.first_opt((self.model).parameters(), lr=self.lr1)\n",
    "        if self.second_opt: trainer_2 = self.second_opt(self.model.parameters(), lr=self.lr2)\n",
    "        for epoch in range(self.num_epochs):\n",
    "            start = time.time()\n",
    "            self.first_train = self.training(self.train_loader, trainer=trainer_1)\n",
    "            self.second_train = self.training(self.train_loader, trainer=trainer_2) if self.second_opt else False \n",
    "            self.last_train = self.training(self.test_loader, mode='eval')\n",
    "            time_spent = time.time() - start\n",
    "            self.printer(epoch, time_spent)\n",
    "            \n",
    "    \n",
    "    def training(self, data, trainer=False, mode='train'):\n",
    "        self.model.eval() if mode == 'eval' else self.model.train()\n",
    "        dict = {'loss':0, 'tp':0, 'iters':0, 'len':0}\n",
    "        for X, y in data:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            if mode == 'train': trainer.zero_grad()\n",
    "            predictions = self.model(X)\n",
    "            loss = self.criterion(predictions, y)\n",
    "            loss.backward()\n",
    "            if mode == 'train': trainer.step()\n",
    "            dict = {'loss':(dict['loss']+loss.item()), \n",
    "                    'tp':(dict['tp']+(predictions.argmax(dim=1) == y).sum().item()), \n",
    "                    'iters':(dict['iters']+1), \n",
    "                    'len':(dict['len']+len(X))}\n",
    "        return {'loss':(dict['loss']/dict['iters']), 'acc':(dict['tp']/dict['len'])} \n",
    "            \n",
    "    \n",
    "    def printer (self, epoch, time_spent):\n",
    "        name_1 = self.first_opt.__name__\n",
    "        name_2 = self.second_opt.__name__ if self.second_opt else False\n",
    "        if not epoch:\n",
    "            print('|{: ^8}|{: ^9}|'.format('Epochs','Time') + \\\n",
    "                  '{: ^17}|{: ^16}|'.format('Train '+name_1+' loss', 'Train '+name_1+' acc') + \\\n",
    "                  ('{: ^17}|{: ^16}|'.format('Train '+str(name_2)+' loss', \n",
    "                                             'Train '+str(name_2)+' acc')if self.second_opt else '') + \\\n",
    "                  '{: ^11}|{: ^10}|'.format('Test loss', 'Test acc'))\n",
    "\n",
    "        print('|{: ^8}|{: ^9.4f}|'.format(epoch, time_spent) + \\\n",
    "              '{: ^17.4f}|{: ^16.4%}|'.format(self.first_train['loss'], self.first_train['acc']) + \\\n",
    "              ('{: ^17.4f}|{: ^16.4%}|'.format(self.second_train['loss'], \n",
    "                                               self.second_train['acc'])if self.second_opt else '') + \\\n",
    "              '{: ^11.4f}|{: ^10.4%}|'.format(self.last_train['loss'], self.last_train['acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epochs |  Time   |Train AdamW loss |Train AdamW acc | Train SGD loss  | Train SGD acc  | Test loss | Test acc |\n",
      "|   0    | 78.8442 |     0.5544      |    80.7500%    |     0.3859      |    86.9350%    |  0.3104   | 88.9400% |\n",
      "|   1    | 72.5930 |     0.3719      |    87.4317%    |     0.3241      |    88.9500%    |  0.2743   | 89.9200% |\n",
      "|   2    | 70.5551 |     0.3242      |    88.9317%    |     0.2947      |    90.1083%    |  0.2560   | 90.6600% |\n",
      "|   3    | 68.9690 |     0.2970      |    89.8350%    |     0.2677      |    90.9050%    |  0.2468   | 91.1300% |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a1ba7029827b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNetPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_opt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_opt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.001\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-1b6451d49cb4>\u001b[0m in \u001b[0;36mtrain_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainer_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msecond_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainer_2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msecond_opt\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtime_spent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-1b6451d49cb4>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(self, data, trainer, mode)\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             dict = {'loss':(dict['loss']+loss.item()), \n\u001b[0m\u001b[0;32m     37\u001b[0m                     \u001b[1;34m'tp'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[1;34m'iters'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'iters'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NetPipeline(train, test, model, 5, first_opt=torch.optim.AdamW, lr1=.01, second_opt=torch.optim.SGD, lr2=.001 ).train_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Лекция 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
